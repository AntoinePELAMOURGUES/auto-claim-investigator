# üïµÔ∏è‚Äç‚ôÇÔ∏è Auto-Claim Investigator

Pipeline d'Analyse de Sinistres Automatis√© par GenAI (Snowflake Cortex)

# üéØ Vision du Projet

Ce projet d√©montre comment moderniser le traitement des sinistres automobiles en transformant des donn√©es non structur√©es (r√©cits d'accidents en texte libre) en d√©cisions m√©tier structur√©es (responsabilit√© 0%, 50%, 100%) gr√¢ce √† l'IA G√©n√©rative int√©gr√©e au Data Warehouse.

## Objectif Business :

- R√©duire le temps de lecture des constats amiables.

- Standardiser la prise de d√©cision sur la responsabilit√©.

- D√©tecter les anomalies via un scoring automatique.

# üèó Architecture Technique

Le pipeline suit une architecture ELT moderne (Extract, Load, Transform) orchestr√©e par dbt et propuls√©e par Snowflake.

```mermaid
graph LR
    subgraph "Ingestion (Python)"
        A[Generate Fake Claims] -->|JSON| B[Local Data]
        B -->|Secure Upload| C[(Snowflake Internal Stage)]
    end

    subgraph "Snowflake Data Cloud"
        C -->|COPY INTO| D[RAW Layer]
        D -->|dbt transformation| E[STAGING Layer]
        E -->|Snowflake CORTEX<br>Mistral-Large| F[AI ANALYSIS Layer]
        F -->|dbt transformation| G[GOLD Dashboard]
    end

    style F fill:#f9f,stroke:#333,stroke-width:2px
```

# üõ† La Stack

- Infrastructure : Snowflake (Standard Edition).

- Transformation : dbt Core (v1.7) avec adaptateur Snowflake.

- Intelligence Artificielle : Snowflake Cortex (Fonctions LLM Serverless : COMPLETE).

- Langage : SQL (90%), Python (G√©n√©ration de donn√©es & Ingestion), Jinja.

- Documentation : dbt Docs.

# üß† Focus : L'IA au service du M√©tier

Le c≈ìur du projet r√©side dans l'utilisation de Snowflake Cortex pour analyser le texte. Aucune sortie de donn√©es hors de la plateforme n'est n√©cessaire (S√©curit√© & Gouvernance).

## Exemple de Prompt Engineering (SQL) :

```sql
SELECT 
    claim_id,
    accident_description,
    SNOWFLAKE.CORTEX.COMPLETE(
        'mistral-large', 
        CONCAT(
            'Tu es un expert en assurance. Analyse le constat suivant. ',
            'D√©termine la responsabilit√© du narrateur (0, 50, 100). ',
            'R√©cit : ', accident_description
        )
    ) AS ai_verdict
FROM staging.claims;
```

**R√©sultat de la transformation :**

| Input (Non structur√©) | Output IA (Structur√©) |
| :--- | :--- |
| *"Je suis sorti de mon stationnement et j'ai heurt√© le v√©hicule B."* | **100% Responsable** |
| *"J'√©tais √† l'arr√™t au feu rouge, on m'a percut√© par l'arri√®re."* | **0% Responsable** |

# üöÄ Installation & D√©marrage

### Pr√©-requis

- Python 3.10+

- Compte Snowflake avec acc√®s Cortex activ√©.

## 1. Cloner et Configurer

```Bash

git clone https://github.com/VOTRE_USER/auto-claim-investigator.git
cd auto-claim-investigator
pip install -r requirements.txt 2. S√©curit√© (.env)
Cr√©ez un fichier .env √† la racine (ne jamais commiter les cr√©dentials !) :

SNOWFLAKE_ACCOUNT=ORG-ACCOUNT
SNOWFLAKE_USER=votre_user
SNOWFLAKE_PASSWORD=votre_mdp
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=INSURANCE_DB 3. Ex√©cution du Pipeline
```

## 2. G√©n√©rer et Ing√©rer les donn√©es (Python)

```Bash
cd scripts
python generate_fake_claims.py
python ingest_data.py
```

## 3. Transformer et Analyser (dbt)

```Bash
cd ../dbt_claims
dbt run
```

# üìä Documentation & Lineage

```Bash
dbt docs generate
dbt docs serve
```

# üë§ Auteur

Antoine - Data Engineer / Tech Lead

Projet r√©alis√© dans le cadre d'un Proof of Concept (POC) technique d√©montrant l'int√©gration de l'IA G√©n√©rative dans les workflows Data Engineering modernes.
